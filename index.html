<!DOCTYPE html>
<html lang="fr">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link rel="manifest" href="manifest.json">
    <title>Assistant IA Vocal</title>
    <style>
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, 'Helvetica Neue', Arial, sans-serif;
            margin: 0;
            height: 100vh;
            display: flex;
            justify-content: center;
            align-items: center;
            color: white;
            text-align: center;
            background-color: #1a1a1d;
            background-image: url('https://images.unsplash.com/photo-1550745165-9bc0b252726a?q=80&w=1920&auto-format&fit=crop');
            background-size: cover;
            background-position: center;
        }
        
        #assistant-card {
            width: 90%;
            max-width: 400px;
            padding: 40px 20px;
            border-radius: 25px;
            border: 1px solid rgba(255, 255, 255, 0.2);
            background-color: rgba(25, 25, 29, 0.6);
            backdrop-filter: blur(15px);
            -webkit-backdrop-filter: blur(15px);
            box-shadow: 0 8px 32px 0 rgba(0, 0, 0, 0.37);
            display: flex;
            flex-direction: column;
            align-items: center;
            gap: 20px;
            cursor: pointer;
            transition: box-shadow 0.2s ease-in-out;
        }
        
        #assistant-card.active-feedback {
            box-shadow: 0 8px 32px 0 rgba(0, 0, 0, 0.37), inset 0 0 0 2px rgba(255, 255, 255, 0.8);
        }

        #mic-container {
            transition: transform 0.2s ease;
        }
        #assistant-card:hover #mic-container {
            transform: scale(1.1);
        }

        #mic-icon { width: 50px; height: 50px; }

        #status {
            font-size: 1.2em;
            margin: 0;
            min-height: 1.5em;
            max-height: 200px;
            overflow-y: auto;
            user-select: none;
            -webkit-user-select: none;
            pointer-events: none;
        }
        
        #listening-animation { display: none; height: 50px; align-items: center; justify-content: center; gap: 8px; }
        .sound-wave { display: block; width: 5px; height: 8px; border-radius: 3px; background-color: white; animation: sound-wave-animation 1.2s infinite ease-in-out; }
        @keyframes sound-wave-animation { 0%, 40%, 100% { transform: scaleY(0.5); } 20% { transform: scaleY(2.5); } }
        .sound-wave:nth-child(2) { animation-delay: -1.0s; }
        .sound-wave:nth-child(3) { animation-delay: -0.8s; }
        .sound-wave:nth-child(4) { animation-delay: -0.6s; }
        
        #wiki-button { position: fixed; top: 25px; left: 50%; transform: translateX(-50%); background-color: #fff; color: #222; padding: 12px 24px; border-radius: 30px; text-decoration: none; font-size: 1em; font-weight: bold; box-shadow: 0 4px 10px rgba(0,0,0,0.3); transition: all 0.2s ease-in-out; z-index: 100; }
        #wiki-button:hover { background-color: #eee; transform: translateX(-50%) scale(1.05); }
        #stop-instruction { display: block; position: fixed; bottom: 80px; left: 0; width: 100%; margin: 0; padding: 10px 0; background-color: rgba(0, 0, 0, 0.3); font-size: 1em; font-weight: normal; z-index: 99; }
        #interrupt-button { position: fixed; bottom: 0; left: 0; width: 100%; height: 80px; border: none; border-radius: 0; transform: none; background-color: #DB4437; color: white; font-size: 1.5em; font-weight: bold; letter-spacing: 2px; cursor: pointer; display: flex; justify-content: center; align-items: center; z-index: 100; transition: background-color 0.2s ease-in-out; }
        #interrupt-button:hover { background-color: #C33D2E; }
    </style>
</head>
<body>
    
    <a href="#" id="wiki-button" target="_blank" style="display: none;">
        Consulter sur Wikipédia
    </a>

    <div id="assistant-card">
        <div id="mic-container">
            <svg id="mic-icon" xmlns="http://www.w.org/2000/svg" viewBox="0 0 384 512">
                <path fill="white" d="M192 0C139 0 96 43 96 96V256c0 53 43 96 96 96s96-43 96-96V96c0-53-43-96-96-96zM64 216c0-13.3-10.7-24-24-24s-24 10.7-24 24v40c0 89.1 66.2 162.7 152 174.4V464H120c-13.3 0-24 10.7-24 24s10.7 24 24 24h144c13.3 0 24-10.7 24-24s-10.7-24-24-24H216V430.4c85.8-11.7 152-85.3 152-174.4V216c0-13.3-10.7-24-24-24s-24 10.7-24 24v40c0 70.7-57.3 128-128 128s-128-57.3-128-128V216z"/>
            </svg>
        </div>
        <div id="listening-animation">
            <span class="sound-wave"></span><span class="sound-wave"></span><span class="sound-wave"></span><span class="sound-wave"></span>
        </div>
        <p id="status">Comment puis-je vous aider ?</p>
    </div>

    <p id="stop-instruction">Pour arrêter la conversation dites-moi "j'arrête"</p>

    <button id="interrupt-button">STOP</button>
    
    <script>
        const assistantCard = document.getElementById('assistant-card');
        const micContainer = document.getElementById('mic-container');
        const statusDiv = document.getElementById('status');
        const listeningAnimation = document.getElementById('listening-animation');
        const wikiButton = document.getElementById('wiki-button');
        const interruptButton = document.getElementById('interrupt-button');
        
        const API_KEY = "AIzaSyAUqkLGpC-N4bhPS42HSAMTCM54ciO9XEI"; 
        
        const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
        const synthesis = window.speechSynthesis;

        let isConfirmingStop = false;
        let autoRestart = false; // MODIFIÉ : Variable pour gérer le redémarrage

        if (!SpeechRecognition || !synthesis) {
            statusDiv.textContent = "API vocales non supportées.";
            micContainer.style.display = 'none';
        } else {
            const recognition = new SpeechRecognition();
            recognition.lang = 'fr-FR';
            recognition.continuous = false;

            function speak(text, onEndCallback) {
                autoRestart = false; // On met en pause le redémarrage quand l'IA parle
                if (synthesis.speaking) synthesis.cancel();
                setTimeout(() => {
                    const utterance = new SpeechSynthesisUtterance(text);
                    utterance.lang = 'fr-FR';
                    utterance.onend = () => { if (onEndCallback) onEndCallback(); };
                    synthesis.speak(utterance);
                }, 100);
            }
            
            async function searchWikipedia(subject) {
                if (!subject) return;
                const endpoint = `https://fr.wikipedia.org/w/api.php?action=opensearch&search=${encodeURIComponent(subject)}&limit=1&namespace=0&format=json&origin=*`;
                try {
                    const response = await fetch(endpoint);
                    const data = await response.json();
                    const url = data[3]?.[0];
                    if (url) {
                        wikiButton.href = url;
                        wikiButton.style.display = 'inline-block';
                    }
                } catch (error) { console.error("Erreur API Wikipédia:", error); }
            }

            async function callGeminiAPI(prompt) {
                autoRestart = false; // On met en pause le redémarrage pendant que l'IA réfléchit
                statusDiv.textContent = "L'IA réfléchit...";
                wikiButton.style.display = 'none';
                
                const API_URL = `https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent?key=${API_KEY}`;
                
                const fullPrompt = `Réponds à la question suivante. En plus de ta réponse, identifie l'entité (personne, lieu, concept) la plus pertinente de ta réponse pour une recherche Wikipédia. Formate ta sortie EXCLUSIVEMENT en JSON avec deux clés : "reponse" pour ton texte, et "sujet" pour l'entité. Si aucun sujet n'est pertinent, mets "sujet" à null. La question est : "${prompt}"`;

                try {
                    const res = await fetch(API_URL, {
                        method: "POST",
                        headers: { "Content-Type": "application/json" },
                        body: JSON.stringify({ contents: [{ parts: [{ text: fullPrompt }]}] })
                    });

                    if (!res.ok) {
                        const errorData = await res.json();
                        throw new Error(errorData.error.message || `Erreur ${res.status}`);
                    }
                    
                    const data = await res.json();
                    let apiContent = data?.candidates?.[0]?.content?.parts?.[0]?.text || "";
                    
                    let parsedResponse;
                    const jsonMatch = apiContent.match(/{[\s\S]*}/);

                    if (jsonMatch) {
                        try { parsedResponse = JSON.parse(jsonMatch[0]); } 
                        catch (e) { parsedResponse = { reponse: apiContent, sujet: null }; }
                    } else { parsedResponse = { reponse: apiContent, sujet: null }; }

                    const { reponse, sujet } = parsedResponse;

                    if (reponse) {
                        statusDiv.textContent = reponse;
                        searchWikipedia(sujet);
                        const cleanTextForSpeech = reponse.replaceAll('*', '');
                        speak(cleanTextForSpeech, () => {
                            startListeningUI();
                            autoRestart = true; // On réactive le redémarrage après la réponse
                            recognition.start();
                        });
                    } else { throw new Error("Aucune réponse textuelle reçue de l'API."); }

                } catch (err) {
                    console.error("Erreur Gemini:", err);
                    statusDiv.textContent = `Erreur: ${err.message}`;
                    speak(`Une erreur est survenue.`);
                }
            }

            function startListeningUI() { micContainer.style.display = 'none'; listeningAnimation.style.display = 'flex'; statusDiv.textContent = "Je vous écoute..."; }
            
            function stopListeningUI() { micContainer.style.display = 'block'; listeningAnimation.style.display = 'none'; }

            const startVocalAssistant = (event) => {
                if (event) event.preventDefault();
                
                assistantCard.classList.add('active-feedback');
                setTimeout(() => assistantCard.classList.remove('active-feedback'), 200);

                if (listeningAnimation.style.display === 'flex') {
                    return;
                }
                
                wikiButton.style.display = 'none';
                speak("Bonjour", () => { 
                    startListeningUI(); 
                    autoRestart = true; // On active le mode redémarrage
                    recognition.start(); 
                });
            };

            assistantCard.addEventListener('mousedown', startVocalAssistant); 
            assistantCard.addEventListener('touchstart', startVocalAssistant);
            
            interruptButton.addEventListener('click', () => {
                autoRestart = false; // On désactive le redémarrage
                synthesis.cancel();
                isConfirmingStop = true;
                speak("Voulez-vous continuer à parler ?", () => {
                    startListeningUI();
                    recognition.start();
                });
            });

            recognition.onresult = (event) => { 
                autoRestart = false; // On a reçu un résultat, on met en pause le redémarrage
                const transcript = event.results[0][0].transcript.toLowerCase().trim(); 

                if (isConfirmingStop) {
                    isConfirmingStop = false;
                    if (transcript.includes("oui")) {
                        speak("D'accord, posez votre question.", () => {
                            startListeningUI();
                            autoRestart = true; // On réactive si l'utilisateur veut continuer
                            recognition.start();
                        });
                    } else {
                        statusDiv.textContent = "Au revoir !";
                        speak("Au revoir");
                    }
                } else {
                    if (transcript.includes("j'arrête") || transcript.includes("arrête") || transcript.includes("arrêter")) { 
                        statusDiv.textContent = "Au revoir !"; 
                        speak("Au revoir"); 
                    } else { 
                        callGeminiAPI(transcript); 
                    } 
                }
            };
            
            /* MODIFIÉ : Gestion du redémarrage automatique */
            recognition.onend = () => {
                if (autoRestart) {
                    recognition.start(); // Si le redémarrage est activé, on relance
                } else {
                    stopListeningUI(); // Sinon, on arrête l'interface normalement
                }
            };

            recognition.onerror = (event) => {
                console.error("Erreur reconnaissance:", event.error);
                if (event.error === 'no-speech') {
                    statusDiv.textContent = "Je n'ai rien entendu, je relance l'écoute...";
                    autoRestart = true; // On s'assure que le redémarrage est bien activé
                } else {
                    statusDiv.textContent = "Une erreur est survenue durant l'écoute.";
                    autoRestart = false; // On arrête en cas de vraie erreur
                }
            };
        }
    </script>
    <script>
      if ('serviceWorker' in navigator) {
        window.addEventListener('load', () => {
          navigator.serviceWorker.register('/sw.js')
            .then(registration => {
              console.log('Service Worker enregistré avec succès !');
            })
            .catch(err => {
              console.log('Échec de l\'enregistrement du Service Worker: ', err);
            });
        });
      }
     </script>
     
<!-- Bouton plein écran en SVG -->
<button id="fullscreenBtn" style="
  position: fixed;
  top: 10px;
  right: 10px;
  background: none;
  border: none;
  cursor: pointer;
  z-index: 9999;
  width: 40px;
  height: 40px;
">
  <!-- Icône plein écran -->
  <svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke="currentColor" stroke-width="2" width="100%" height="100%">
    <path stroke-linecap="round" stroke-linejoin="round" d="M8 3H5a2 2 0 00-2 2v3m0 8v3a2 2 0 002 2h3m8-16h3a2 2 0 012 2v3m0 8v3a2 2 0 01-2 2h-3"/>
  </svg>
</button>

<script>
document.getElementById('fullscreenBtn').addEventListener('click', () => {
  if (!document.fullscreenElement) {
    document.documentElement.requestFullscreen().catch(err => {
      console.error(`Erreur: ${err.message}`);
    });
  } else {
    document.exitFullscreen();
  }
});
</script>

</body>
      </html>
